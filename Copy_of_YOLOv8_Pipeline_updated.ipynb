{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rain1618/Global-Health-Hack/blob/main/Copy_of_YOLOv8_Pipeline_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Main task:** train front cam with real life images to identify the following classes:\n",
        "\n",
        " [\"Abydos Symbol\", \"Buoy\", \"Earth Symbol\", \"Gate\", \"Lane Marker\", \"Octagon Table\"]\n",
        "\n",
        "** Secondary task:** train different model for the down cam to identify the following classes:\n",
        "  [\"Lane Marker\", \"Octagon Table\"],\n",
        "\n",
        "  Should output a .py model file at the end.\n",
        "\n",
        "TODO:\n",
        "\n",
        "*   Avoid sample_data getting downloaded when we import the YOLO model\n",
        "*   Automate uploading data and changing name and directory\n",
        "*   Make the data.yaml adapt to the classes of the dataset\n",
        "*   Make shuffle function get a similar similar sample size of images for every class in the train, test and val splits. Split by class and then combine together to make sure the datasets are balanced\n",
        "*   In \"Front cam\" (176 images) there's goofy images of buoy where the buoy is not in water (sort by updated)\n",
        "*   Do some sort of data parallelism, model parallelism, and pipeline parallelism to speed up training time?\n",
        "\n"
      ],
      "metadata": {
        "id": "_22YU2slbQv2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Questions\n",
        "\n",
        "*  image filtering techniques to increase the quality of the footage?"
      ],
      "metadata": {
        "id": "ZvS5GQUKT6zb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Duke dataset**\n",
        "*    \"pool...\" = real image\n",
        "*    \"camera...\" = simulation\n",
        "*    Some of their sim images lowkey really good tho"
      ],
      "metadata": {
        "id": "2qAELukyWkyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**More datasets!**\n",
        "\n",
        "https://github.com/beaverauv/robosub_transdec_dataset/tree/master\n",
        "\n",
        "https://app.box.com/folder/218274654447"
      ],
      "metadata": {
        "id": "_nnJpKjwUxKy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAQ76bSTy48-"
      },
      "source": [
        "# Install dependencies, set up folder structure, import necessary librairies, generate data.yaml file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "editable": true,
        "id": "I2wYwdPAyklw",
        "outputId": "86270a88-7b95-438b-fddc-059012d0aef0",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.3)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.8.1.78)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (4.5.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (23.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.2.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.0.207)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.44.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "mkdir: cannot create directory ‘data’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented/train’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented/test’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented/val’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented/train/images’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented/test/images’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented/val/images’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented/train/labels’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented/test/labels’: File exists\n",
            "mkdir: cannot create directory ‘data/augmented/val/labels’: File exists\n"
          ]
        }
      ],
      "source": [
        "!pip install albumentations\n",
        "!pip install opencv-python\n",
        "!pip install ultralytics\n",
        "!mkdir data\n",
        "!mkdir data/augmented\n",
        "# !mkdir data/raw\n",
        "!mkdir data/augmented/train\n",
        "!mkdir data/augmented/test\n",
        "!mkdir data/augmented/val\n",
        "!mkdir data/augmented/train/images\n",
        "!mkdir data/augmented/test/images\n",
        "!mkdir data/augmented/val/images\n",
        "!mkdir data/augmented/train/labels\n",
        "!mkdir data/augmented/test/labels\n",
        "!mkdir data/augmented/val/labels\n",
        "# !mkdir data/raw/images\n",
        "# !mkdir data/raw/labels\n",
        "# !rm -r sample_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "editable": true,
        "id": "V3-T5zOB0sEi",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import albumentations as A\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import shutil\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "editable": true,
        "id": "N0SHMX1C2ZuL",
        "tags": []
      },
      "outputs": [],
      "source": [
        "with open('data.yaml', 'w+') as f:\n",
        "    f.write(\"train: /content/data/augmented/train/images\\n\")\n",
        "    f.write(\"test: /content/data/augmented/test/images\\n\")\n",
        "    f.write(\"val: /content/data/augmented/val/images\\n\")\n",
        "    f.write(\"nc: 6\\n\")\n",
        "    f.write('names: [\"Abydos Symbol\", \"Buoy\", \"Earth Symbol\", \"Gate\", \"Lane Marker\", \"Octagon Table\"]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COpq9wZczt1G"
      },
      "source": [
        "# Augment data in /raw folder, put augmented dataset in /augmented folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHa1-UEe0FuN"
      },
      "source": [
        "Define individual augmentation functions and image file input/ouput helper functions. Each augmentation is a function that expects a list of (image, label) tuples, and returns the original tuples as well as all augmented versions of each (image, label) tuple in a larger list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "editable": true,
        "id": "ffYKzEDIz225",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#given a list of samples, make two copies of each sample that are darker/brighter to simulate differently lit environments\n",
        "def brightnessAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        transform = A.Compose([ A.augmentations.transforms.ColorJitter (brightness=(1.05, 1.05), contrast=0, saturation=0, hue=0, always_apply=True) ])\n",
        "        bright_img = transform(image=image)[\"image\"]\n",
        "        transform = A.Compose([ A.augmentations.transforms.ColorJitter (brightness=(0.95, 0.95), contrast=0, saturation=0, hue=0, always_apply=True) ])\n",
        "        dark_img = transform(image=image)[\"image\"]\n",
        "        out.append(bright_img)\n",
        "        out.append(dark_img)\n",
        "    return out\n",
        "\n",
        "#given a list of samples, make a copy of each sample but more blurred to simulate objects out of focus, dirty lenses, and backscattering\n",
        "def blurAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        ksize = (10, 10) # lower to lower blur\n",
        "        blurred_img = cv2.blur(image, ksize)\n",
        "        out.append(blurred_img)\n",
        "    return out\n",
        "\n",
        "#given a list of samples, make a copy of each sample but with a lower contrast image to simulate backscattering and over/under-exposure\n",
        "def contrastAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        transform = A.Compose([ A.augmentations.transforms.ColorJitter (brightness=0, contrast=(0.1, 0.1), saturation=0, hue=0, always_apply=True) ])\n",
        "        decontrasted_img = transform(image=image)[\"image\"]\n",
        "        out.append(decontrasted_img)\n",
        "    return out\n",
        "\n",
        "#given a list of samples, make a copy of each sample but with camera noise added to the image to simulate different camera feeds\n",
        "def noiseAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        transform = A.Compose([ A.augmentations.transforms.ISONoise(color_shift=(0.01, 0.01), intensity=(0.8, 0.8), always_apply=True) ])\n",
        "        noisy_img = transform(image=image)[\"image\"]\n",
        "        out.append(noisy_img)\n",
        "    return out\n",
        "\n",
        "#given a list of samples, make a copy of each sample but with the image downscaled (lower resolution of image) to simulate lower quality cameras/images\n",
        "def resolutionAugment(images):\n",
        "    out = []\n",
        "    for image in images:\n",
        "        #interpolation=A.augmentations.transforms.Interpolation(downscale=cv2.INTER_NEAREST, upscale=cv2.INTER_NEAREST)\n",
        "        transform = A.Compose([ A.augmentations.transforms.Downscale(scale_min=0.25, scale_max=0.25, always_apply=True) ])\n",
        "        low_res_img = transform(image=image)[\"image\"]\n",
        "        out.append(low_res_img)\n",
        "    return out\n",
        "\n",
        "#increase intensity of blues in given image\n",
        "def make_bluer(img, color_shift_intensity):\n",
        "    img_b, img_g, img_r = cv2.split(img) #split by channel\n",
        "    img_b = np.uint16(img_b)\n",
        "    img_b += color_shift_intensity\n",
        "    np.clip(img_b, 0, 255, out=img_b)\n",
        "    img_b = np.uint8(img_b)\n",
        "    img = cv2.merge((img_b, img_g, img_r)) #merge adjusted channels\n",
        "    del img_b\n",
        "    del img_g\n",
        "    del img_r\n",
        "    return img\n",
        "\n",
        "#increase intensity of greens in given image\n",
        "def make_greener(img, color_shift_intensity):\n",
        "    img_b, img_g, img_r = cv2.split(img) #split by channel\n",
        "    img_g = np.uint16(img_g)\n",
        "    img_g += color_shift_intensity\n",
        "    np.clip(img_g, 0, 255, out=img_g)\n",
        "    img_g = np.uint8(img_g)\n",
        "    img = cv2.merge((img_b, img_g, img_r)) #merge adjusted channels\n",
        "    del img_b\n",
        "    del img_g\n",
        "    del img_r\n",
        "    return img\n",
        "\n",
        "#given a list of samples, make two copies of each sample (one bluer, one greener) to simulate different pools + color attenuation\n",
        "def colorAugment(images):\n",
        "    out = []\n",
        "    color_shift_intensity = int(255*0.1)\n",
        "    for image in images:\n",
        "        blue_img = make_bluer(image, color_shift_intensity)\n",
        "        green_img = make_greener(image, color_shift_intensity)\n",
        "        out.append(blue_img)\n",
        "        out.append(green_img)\n",
        "    return out\n",
        "\n",
        "#remove all files/folders in folder\n",
        "def clearFolder(folder):\n",
        "    #get all directory/filenames in folder\n",
        "    for filename in os.listdir(folder):\n",
        "        file_path = os.path.join(folder, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                #delete all files\n",
        "                os.unlink(file_path)\n",
        "            elif os.path.isdir(file_path):\n",
        "                #recursively delete everything in sub-folders\n",
        "                shutil.rmtree(file_path)\n",
        "        except Exception as e:\n",
        "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "\n",
        "#output given samples to given folder so that each image has corresponding label with same filename in /images and /labels subfolders respectively\n",
        "def sendToFolders(samples, output_folder):\n",
        "    #remove all files/folders in output folders\n",
        "    clearFolder(output_folder + \"/images\")\n",
        "    clearFolder(output_folder + \"/labels\")\n",
        "    instance_count = 0 #keep track of instance count for filename\n",
        "    for sample in samples:\n",
        "        image, label = sample\n",
        "        #write image to file in /images\n",
        "        cv2.imwrite(output_folder + '/images/img' + str(instance_count) + '.png', image)\n",
        "        #write label to file in /labels\n",
        "        with open(output_folder + '/labels/img' + str(instance_count) + '.txt', 'w+') as f:\n",
        "            #each box gets its own line\n",
        "            for box in label:\n",
        "                f.write(box)\n",
        "        instance_count += 1\n",
        "\n",
        "#given array of image/label arrays, and an integer of how to split the data, returns the dataset split accordingly\n",
        "def splitData(samples, splits):\n",
        "    #for now we just shuffle the data to hopefully get a similar similar sample size\n",
        "    # of images for every class in the train, test and val splits\n",
        "    #ideally in the future we should split by class and then combine together to make sure the datasets are balanced\n",
        "\n",
        "    #shuffle data\n",
        "    random.shuffle(samples)\n",
        "    #get indices for split\n",
        "    splits = [int(len(samples)*s) for s in splits]\n",
        "    #return split data\n",
        "    return samples[:splits[0]], samples[splits[0]:splits[0]+splits[1]], samples[splits[0]+splits[1]:]\n",
        "\n",
        "#given a single image and augmentation function, displays the image before and images after augmentation\n",
        "def visualizeAugmentation(img, aug):\n",
        "    #show original image\n",
        "    cv2.imshow('og', img)\n",
        "    cv2.waitKey(0)\n",
        "    #show all augmented images\n",
        "    for augmented in aug([(img, \"\")])[1:]:\n",
        "        cv2.imshow('augmented',augmented[0])\n",
        "        cv2.waitKey(0)\n",
        "\n",
        "#given source dataset folder, loads all images and labels into arrays\n",
        "def loadInputData(source_folder):\n",
        "    samples = []\n",
        "    #get all filenames in the /images subfolder of given source_folder\n",
        "    img_filenames = [f for f in listdir(source_folder + '/images') if isfile(join(source_folder + '/images', f))]\n",
        "    for img_filename in img_filenames:\n",
        "        #load image at that filename\n",
        "        img = cv2.imread(source_folder + '/images/' + img_filename)\n",
        "        #got label filename corresponding to the image\n",
        "        label_filename = os.path.splitext(img_filename)[0] + \".txt\"\n",
        "        #load in the label file contents\n",
        "        with open(source_folder + \"/labels/\" + label_filename) as f:\n",
        "            #build array of bounding boxes (each line its own element)\n",
        "            bounding_boxes = []\n",
        "            for line in f.read().split(\"\\n\"):\n",
        "                bounding_boxes.append(line)\n",
        "        #add image and label to sample set\n",
        "        samples.append( (img, bounding_boxes) )\n",
        "    del img_filenames\n",
        "    return samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yHQqr4W4XxPU"
      },
      "outputs": [],
      "source": [
        "def get_file_names(source_folder):\n",
        "    label_filenames = []\n",
        "    img_filenames = [f for f in listdir(source_folder + '/images') if isfile(join(source_folder + '/images', f))]\n",
        "    for img_filename in img_filenames:\n",
        "        label_filenames.append(os.path.splitext(img_filename)[0] + \".txt\")\n",
        "\n",
        "    return np.array(img_filenames), np.array(label_filenames)\n",
        "\n",
        "def split_file_names(images,labels,splits):\n",
        "    perm = np.random.permutation(len(images))\n",
        "    images = images[perm]\n",
        "    labels = labels[perm]\n",
        "    splits = [int(len(images)*s) for s in splits]\n",
        "    train_images = images[:splits[0]]\n",
        "    train_labels = labels[:splits[0]]\n",
        "    val_images = images[splits[0]: splits[0] + splits[1]]\n",
        "    val_labels = labels[splits[0]: splits[0] + splits[1]]\n",
        "    test_images = images[splits[0] + splits[1]:]\n",
        "    test_labels = labels[splits[0] + splits[1]:]\n",
        "    return train_images, train_labels, val_images, val_labels, test_images, test_labels\n",
        "\n",
        "def get_augs(img_filename,source_folder):\n",
        "    img = cv2.imread(source_folder + '/images/' + img_filename)\n",
        "    prob = 0.5\n",
        "    augs = [img]\n",
        "    if(np.random.rand() > prob):\n",
        "        augs = augs + colorAugment([img])\n",
        "    if(np.random.rand() > prob):\n",
        "        augs = augs + brightnessAugment(augs)\n",
        "    if(np.random.rand() > prob):\n",
        "        augs = augs + contrastAugment(augs)\n",
        "    if(np.random.rand() > prob):\n",
        "        augs = augs + blurAugment(augs)\n",
        "    return augs\n",
        "\n",
        "def do_augs_and_export(img_filenames,label_filenames,source_folder,output_folder):\n",
        "    name_num = 1\n",
        "    for (img_filename,label_filename) in zip(img_filenames,label_filenames):\n",
        "        augs = get_augs(img_filename,source_folder)\n",
        "        with open(source_folder + \"/labels/\" + label_filename) as f:\n",
        "            #build array of bounding boxes (each line its own element)\n",
        "            bounding_boxes = f.read()\n",
        "        for aug in augs:\n",
        "            cv2.imwrite(output_folder + '/images/img' + str(name_num) + '.png', aug)\n",
        "            with open(output_folder + '/labels/img' + str(name_num) + '.txt',\"w+\") as f:\n",
        "                f.write(bounding_boxes)\n",
        "            name_num+=1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get data from roboflow: Go to Versions > Export Dataset > Choose Format: YOLOv5 > Click \"show download code\" > Continue > Copy-paste the download code below\n",
        "#Change name of folder --> write code to do this after\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"Id86zM4cvFb8WmWN0N1N\")\n",
        "project = rf.workspace(\"auv2024\").project(\"front-cam-real\")\n",
        "dataset = project.version(1).download(\"yolov5\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8tP5PdblZW1U",
        "outputId": "7dd2d22e-417e-47a6-ba9a-1b0244225611"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.9-py3-none-any.whl (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2023.7.22)\n",
            "Collecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/178.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n",
            "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Collecting pyparsing==2.4.7 (from roboflow)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Collecting supervision (from roboflow)\n",
            "  Downloading supervision-0.16.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.2/72.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-magic (from roboflow)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.44.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.3)\n",
            "Installing collected packages: python-magic, python-dotenv, pyparsing, opencv-python-headless, idna, cycler, chardet, supervision, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.8.1.78\n",
            "    Uninstalling opencv-python-headless-4.8.1.78:\n",
            "      Successfully uninstalled opencv-python-headless-4.8.1.78\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "Successfully installed chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 pyparsing-2.4.7 python-dotenv-1.0.0 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.9 supervision-0.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "chardet",
                  "cv2",
                  "cycler",
                  "idna",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Front-cam-real-1 to yolov5pytorch:: 100%|██████████| 15988/15988 [00:00<00:00, 47968.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Front-cam-real-1 in yolov5pytorch:: 100%|██████████| 415/415 [00:00<00:00, 5995.33it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Do the bash stuff to rename/move the images\n",
        "!rm -r sample_data\n",
        "#rename 'old-name-dir' new-name-dir old-name-dir --> RENAME TRAIN\n",
        "!mv /content/Front-cam-real-1/train/ /content/data/raw\n",
        "!rm -r Front-cam-real-1\n",
        "#Check if we need the yaml file in Front-cam-real-1\n",
        "\n"
      ],
      "metadata": {
        "id": "CcVUzx2bsY67"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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))"
      ],
      "metadata": {
        "id": "UALJIL396R8Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "M6f4fmIgXxPU"
      },
      "outputs": [],
      "source": [
        "train_test_val_split = (0.7, 0.2, 0.1)\n",
        "out_folder = \"data/augmented\"\n",
        "in_folder = \"data/raw\"\n",
        "\n",
        "img_names, label_names = get_file_names(in_folder)\n",
        "train_images, train_labels, val_images, val_labels, test_images, test_labels = split_file_names(img_names,label_names,train_test_val_split)\n",
        "do_augs_and_export(train_images,train_labels,in_folder,out_folder + \"/train\")\n",
        "do_augs_and_export(val_images,val_labels,in_folder,out_folder + \"/val\")\n",
        "do_augs_and_export(test_images,test_labels,in_folder,out_folder + \"/test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "NY5fTW4G02T0",
        "tags": []
      },
      "source": [
        "Load in all files from /raw folder, pass list of images sequentially through each augmentation function, then output final images to /augmented folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "id": "uByRW0J20W8e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# train_test_val_split = (0.7, 0.2, 0.1)\n",
        "# out_folder = \"data/augmented\"\n",
        "# in_folder = \"data/raw\"\n",
        "\n",
        "# print(\"Loading data...\")\n",
        "# data = loadInputData(in_folder)\n",
        "\n",
        "#FOR TESTING uncomment to visualize individual augmentations\n",
        "#visualizeAugmentation(data[0][0], colorAugment)\n",
        "#exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoHfG0GZXxPV"
      },
      "outputs": [],
      "source": [
        "# def do_all_augs(stuff):\n",
        "#     stuff = colorAugment(stuff)\n",
        "#     stuff = brightnessAugment(stuff)\n",
        "#     sutff = contrastAugment(stuff)\n",
        "#     return blurAugment(stuff)\n",
        "\n",
        "# train, test, val = splitData(data, train_test_val_split)\n",
        "\n",
        "# # print(\"Augmenting color...\")\n",
        "# data = colorAugment(data) # times 3\n",
        "# print(\"Augmenting brightness...\")\n",
        "# data = brightnessAugment(data) # times 3\n",
        "# print(\"Augmenting contrast...\")\n",
        "# data = contrastAugment(data) # times 2\n",
        "# #print(\"Augmenting blur...\")\n",
        "# #data = blurAugment(data) # times 2\n",
        "# print(\"Splitting data...\")\n",
        "\n",
        "# train = do_all_augs(train)\n",
        "# test = do_all_augs(test)\n",
        "# val = do_all_augs(val)\n",
        "\n",
        "# print(\"Exporting training data...\")\n",
        "# sendToFolders(train, out_folder + \"/train\")\n",
        "# print(\"Exporting test data...\")\n",
        "# sendToFolders(test, out_folder + \"/test\")\n",
        "# print(\"Exporting val data...\")\n",
        "# sendToFolders(val, out_folder + \"/val\")\n",
        "# print(\"Done. Final number of samples: \" + str(len(data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "Ha6R_QiX1mrs",
        "tags": []
      },
      "source": [
        "# Train YOLO model with augmented data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aZBXU0OD7l9b",
        "outputId": "31a20f24-8a38-4a69-b0c0-03131c2ae0c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.device_count())\n",
        "#Ensure this prints true and a number > 0, if not make sure you set hardware accelerator to GPU in Edit > Notebook Settings > Hardware Accelerator\n",
        "# !rm -r runs/detect/train*\n",
        "!mkdir runs\n",
        "!mkdir runs/detect\n",
        "!mkdir runs/detect/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1a82eTY1rFt",
        "outputId": "ea8b9a05-40b8-4cdf-d5d9-5836a0512592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.207 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=360, translate=0.1, scale=0.3, shear=0.0, perspective=0.001, flipud=0.5, fliplr=0.5, mosaic=0.5, mixup=0.5, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3012018 parameters, 3012002 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/augmented/train/labels... 1314 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1314/1314 [00:02<00:00, 565.84it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/augmented/train/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1292, len(boxes) = 5365. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/augmented/val/labels... 327 images, 0 backgrounds, 0 corrupt: 100%|██████████| 327/327 [00:01<00:00, 266.41it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data/augmented/val/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 438, len(boxes) = 1362. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to runs/detect/train3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/50      2.65G      2.091       3.18       2.15          5        640: 100%|██████████| 83/83 [01:16<00:00,  1.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:11<00:00,  1.06s/it]\n",
            "                   all        327       1362       0.41      0.268      0.346      0.142\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/50      2.23G      1.793      2.411      1.949         21        640: 100%|██████████| 83/83 [01:11<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.12it/s]\n",
            "                   all        327       1362      0.661      0.572      0.643      0.319\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/50      2.27G      1.713      2.164      1.891         12        640: 100%|██████████| 83/83 [01:10<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.11it/s]\n",
            "                   all        327       1362      0.685      0.596      0.634      0.225\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/50      2.32G      1.668      2.057      1.851         18        640: 100%|██████████| 83/83 [01:10<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.16it/s]\n",
            "                   all        327       1362      0.822      0.629      0.723      0.302\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/50      2.37G      1.648      2.011      1.841          1        640: 100%|██████████| 83/83 [01:10<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.13it/s]\n",
            "                   all        327       1362      0.801      0.674      0.731      0.373\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/50      2.35G      1.608      1.948      1.828         13        640: 100%|██████████| 83/83 [01:11<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.30it/s]\n",
            "                   all        327       1362      0.885      0.745      0.769      0.347\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/50      2.33G      1.578      1.836      1.774         38        640: 100%|██████████| 83/83 [01:11<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.24it/s]\n",
            "                   all        327       1362       0.89      0.757      0.789      0.357\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/50      2.34G      1.564      1.781      1.788          9        640: 100%|██████████| 83/83 [01:08<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.12it/s]\n",
            "                   all        327       1362      0.839      0.616      0.664      0.332\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/50      2.31G      1.547       1.74      1.761         13        640: 100%|██████████| 83/83 [01:08<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.20it/s]\n",
            "                   all        327       1362      0.886       0.71      0.775      0.449\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/50      2.37G      1.524      1.676      1.746         11        640: 100%|██████████| 83/83 [01:08<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.32it/s]\n",
            "                   all        327       1362      0.852      0.587      0.642      0.269\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/50      2.26G      1.507      1.686      1.738         16        640: 100%|██████████| 83/83 [01:08<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.11it/s]\n",
            "                   all        327       1362      0.845       0.69      0.752        0.4\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/50      2.34G      1.478      1.602      1.697         23        640: 100%|██████████| 83/83 [01:07<00:00,  1.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.18it/s]\n",
            "                   all        327       1362      0.928      0.784      0.827      0.462\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/50       2.3G      1.468      1.602      1.702         11        640: 100%|██████████| 83/83 [01:09<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.37it/s]\n",
            "                   all        327       1362      0.946      0.814      0.842      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/50      2.34G      1.465      1.569        1.7         16        640: 100%|██████████| 83/83 [01:08<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.14it/s]\n",
            "                   all        327       1362       0.92      0.772      0.812      0.497\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/50      2.31G      1.471      1.568      1.709         19        640: 100%|██████████| 83/83 [01:08<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.16it/s]\n",
            "                   all        327       1362      0.925      0.804      0.822      0.425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/50      2.26G      1.443      1.551      1.697          5        640: 100%|██████████| 83/83 [01:08<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.25it/s]\n",
            "                   all        327       1362      0.933      0.802      0.833       0.51\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/50      2.23G      1.426      1.517      1.683         26        640: 100%|██████████| 83/83 [01:08<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.17it/s]\n",
            "                   all        327       1362      0.938      0.825       0.85      0.537\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/50      2.34G       1.42      1.525      1.677         18        640: 100%|██████████| 83/83 [01:07<00:00,  1.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
            "                   all        327       1362      0.923      0.812      0.842      0.464\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/50      2.23G      1.423      1.485      1.684         11        640: 100%|██████████| 83/83 [01:09<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.34it/s]\n",
            "                   all        327       1362      0.933      0.811      0.837      0.495\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/50      2.37G      1.389      1.437      1.633          5        640: 100%|██████████| 83/83 [01:08<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:10<00:00,  1.10it/s]\n",
            "                   all        327       1362      0.919      0.814      0.832      0.477\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/50      2.25G       1.41      1.462      1.668         19        640: 100%|██████████| 83/83 [01:10<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.31it/s]\n",
            "                   all        327       1362      0.951      0.805      0.844      0.563\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/50      2.26G      1.382      1.419      1.632         14        640: 100%|██████████| 83/83 [01:10<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.14it/s]\n",
            "                   all        327       1362      0.948      0.815      0.846       0.53\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/50      2.36G      1.391      1.412      1.646         20        640: 100%|██████████| 83/83 [01:10<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.31it/s]\n",
            "                   all        327       1362      0.938      0.825      0.852      0.552\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/50      2.26G      1.366      1.387      1.629         17        640: 100%|██████████| 83/83 [01:10<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.15it/s]\n",
            "                   all        327       1362      0.964      0.816      0.852      0.487\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/50      2.25G       1.35      1.362      1.624         14        640: 100%|██████████| 83/83 [01:09<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.20it/s]\n",
            "                   all        327       1362      0.941       0.82       0.85       0.54\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/50      2.34G       1.37      1.395      1.624         31        640: 100%|██████████| 83/83 [01:10<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.10it/s]\n",
            "                   all        327       1362      0.941      0.811      0.841      0.579\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/50      2.25G      1.341      1.327      1.596          8        640: 100%|██████████| 83/83 [01:09<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.19it/s]\n",
            "                   all        327       1362       0.96      0.825       0.86       0.56\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/50      2.31G      1.368      1.366      1.621         19        640: 100%|██████████| 83/83 [01:09<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.24it/s]\n",
            "                   all        327       1362      0.961      0.815      0.849      0.534\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/50      2.33G      1.334      1.333      1.602         20        640: 100%|██████████| 83/83 [01:08<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.21it/s]\n",
            "                   all        327       1362      0.973      0.829       0.87      0.568\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/50      2.37G      1.342      1.312      1.598         14        640: 100%|██████████| 83/83 [01:09<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.14it/s]\n",
            "                   all        327       1362      0.948      0.819      0.843      0.488\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/50      2.36G       1.32      1.285      1.569         27        640: 100%|██████████| 83/83 [01:10<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.17it/s]\n",
            "                   all        327       1362      0.957       0.82      0.855      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/50      2.25G      1.323      1.302      1.588         22        640: 100%|██████████| 83/83 [01:07<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.18it/s]\n",
            "                   all        327       1362      0.965      0.826      0.868      0.565\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/50      2.26G      1.314      1.285      1.595          9        640: 100%|██████████| 83/83 [01:09<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.30it/s]\n",
            "                   all        327       1362       0.96      0.826      0.861      0.564\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/50      2.31G      1.306      1.265      1.581          8        640: 100%|██████████| 83/83 [01:09<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.15it/s]\n",
            "                   all        327       1362      0.966      0.812      0.855      0.545\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/50      2.26G      1.302      1.239      1.563         18        640: 100%|██████████| 83/83 [01:08<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.15it/s]\n",
            "                   all        327       1362      0.974      0.824      0.864      0.569\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/50      2.37G      1.287      1.258      1.561         25        640: 100%|██████████| 83/83 [01:07<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.19it/s]\n",
            "                   all        327       1362      0.965      0.834      0.871      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/50      2.31G      1.292      1.229      1.563         11        640: 100%|██████████| 83/83 [01:09<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.13it/s]\n",
            "                   all        327       1362       0.97      0.819      0.869      0.544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/50      2.25G       1.28      1.229      1.549         11        640: 100%|██████████| 83/83 [01:08<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.22it/s]\n",
            "                   all        327       1362      0.975       0.82      0.868      0.584\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/50      2.36G      1.276      1.213       1.55         11        640: 100%|██████████| 83/83 [01:09<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.32it/s]\n",
            "                   all        327       1362      0.977      0.824      0.875      0.601\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/50      2.26G      1.255      1.169      1.531         17        640: 100%|██████████| 83/83 [01:08<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.17it/s]\n",
            "                   all        327       1362      0.976      0.822      0.876      0.608\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/50      2.34G     0.9673     0.7627      1.315          7        640: 100%|██████████| 83/83 [00:53<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.25it/s]\n",
            "                   all        327       1362      0.971      0.818      0.876      0.584\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/50      2.34G     0.9612     0.7069      1.313          4        640: 100%|██████████| 83/83 [00:49<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.22it/s]\n",
            "                   all        327       1362      0.974      0.822      0.872      0.563\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/50      2.33G     0.9369     0.6754      1.299         14        640: 100%|██████████| 83/83 [00:49<00:00,  1.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.38it/s]\n",
            "                   all        327       1362      0.977      0.823      0.876      0.576\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/50      2.34G     0.9274     0.6684      1.287          6        640: 100%|██████████| 83/83 [00:50<00:00,  1.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.43it/s]\n",
            "                   all        327       1362      0.974      0.822      0.881      0.572\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/50      2.32G     0.9175     0.6638      1.269          7        640: 100%|██████████| 83/83 [00:49<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.24it/s]\n",
            "                   all        327       1362      0.974      0.821      0.877      0.604\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/50      2.34G     0.9019     0.6345      1.266          4        640: 100%|██████████| 83/83 [00:50<00:00,  1.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.30it/s]\n",
            "                   all        327       1362      0.969      0.822      0.878      0.598\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/50      2.31G     0.8976     0.6364      1.265          6        640: 100%|██████████| 83/83 [00:49<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.37it/s]\n",
            "                   all        327       1362      0.976      0.822      0.873      0.579\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/50      2.32G     0.8902     0.6133       1.25         10        640: 100%|██████████| 83/83 [00:50<00:00,  1.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.47it/s]\n",
            "                   all        327       1362      0.973      0.822       0.88      0.598\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/50      2.32G      0.882     0.6117      1.246          8        640: 100%|██████████| 83/83 [00:50<00:00,  1.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.33it/s]\n",
            "                   all        327       1362      0.975      0.822      0.881      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      50/50      2.32G     0.8768     0.6071      1.245          5        640: 100%|██████████| 83/83 [00:49<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.27it/s]\n",
            "                   all        327       1362      0.974      0.822      0.878      0.618\n",
            "\n",
            "50 epochs completed in 1.055 hours.\n",
            "Optimizer stripped from runs/detect/train3/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from runs/detect/train3/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating runs/detect/train3/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.207 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006818 parameters, 0 gradients, 8.1 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:10<00:00,  1.01it/s]\n",
            "                   all        327       1362      0.975      0.822      0.881      0.618\n",
            "         Abydos Symbol        327        521      0.938      0.606      0.701      0.454\n",
            "                  Buoy        327        119          1      0.952      0.995      0.827\n",
            "          Earth Symbol        327        514      0.945      0.634      0.732      0.437\n",
            "                  Gate        327        161      0.996      0.919      0.983      0.614\n",
            "         Octagon Table        327         47      0.995          1      0.995       0.76\n",
            "Speed: 0.3ms preprocess, 3.5ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n",
            "Ultralytics YOLOv8.0.207 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006818 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/augmented/val/labels.cache... 327 images, 0 backgrounds, 0 corrupt: 100%|██████████| 327/327 [00:00<?, ?it/s]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 438, len(boxes) = 1362. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 21/21 [00:12<00:00,  1.64it/s]\n",
            "                   all        327       1362      0.975      0.822      0.881      0.619\n",
            "         Abydos Symbol        327        521      0.938      0.606      0.701      0.456\n",
            "                  Buoy        327        119          1      0.952      0.995      0.827\n",
            "          Earth Symbol        327        514      0.945      0.634      0.732      0.438\n",
            "                  Gate        327        161      0.996      0.919      0.983      0.614\n",
            "         Octagon Table        327         47      0.995          1      0.995       0.76\n",
            "Speed: 1.3ms preprocess, 8.4ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train32\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0, 1, 2, 3, 5])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x79137b596b90>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,  0.00081834,  0.00040917,           0],\n",
              "       [          1,           1,           1, ...,           1,           1,           0],\n",
              "       [          1,           1,           1, ...,  0.00057228,  0.00028614,           0],\n",
              "       [          1,           1,           1, ...,     0.54392,     0.54392,           0],\n",
              "       [          1,           1,           1, ...,           1,           1,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.10329,     0.10332,     0.14071, ...,           0,           0,           0],\n",
              "       [    0.22306,     0.22355,      0.3989, ...,           0,           0,           0],\n",
              "       [   0.086512,    0.086539,     0.12073, ...,           0,           0,           0],\n",
              "       [   0.053991,    0.054057,     0.21907, ...,           0,           0,           0],\n",
              "       [     0.6963,      0.6963,     0.81407, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.05492,    0.054938,    0.076624, ...,           1,           1,           1],\n",
              "       [    0.12553,     0.12584,     0.24914, ...,           1,           1,           1],\n",
              "       [   0.045603,    0.045618,    0.065062, ...,           1,           1,           1],\n",
              "       [   0.027744,    0.027779,     0.12301, ...,           1,           1,           1],\n",
              "       [    0.53409,     0.53409,     0.68644, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.86564,     0.86564,     0.85988, ...,           0,           0,           0],\n",
              "       [          1,           1,           1, ...,           0,           0,           0],\n",
              "       [    0.84047,     0.84047,     0.83658, ...,           0,           0,           0],\n",
              "       [          1,           1,           1, ...,           0,           0,           0],\n",
              "       [          1,           1,           1, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: 0.6452775117854928\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.45612,     0.82731,     0.43753,      0.6144,     0.61908,     0.76006])\n",
              "names: {0: 'Abydos Symbol', 1: 'Buoy', 2: 'Earth Symbol', 3: 'Gate', 4: 'Lane Marker', 5: 'Octagon Table'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': 0.9747081040549738, 'metrics/recall(B)': 0.8223399395101311, 'metrics/mAP50(B)': 0.8810104044940728, 'metrics/mAP50-95(B)': 0.6190849681512061, 'fitness': 0.6452775117854928}\n",
              "save_dir: PosixPath('runs/detect/train32')\n",
              "speed: {'preprocess': 1.276769404746706, 'inference': 8.447032456004292, 'loss': 0.0011680323049562788, 'postprocess': 3.190654497992373}\n",
              "task: 'detect'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#UNCOMMENT TO START FROM SCRATCH\n",
        "torch.cuda.empty_cache()\n",
        "model = YOLO(\"yolov8n.pt\")  # load a pretrained model\n",
        "#model = YOLO(\"runs/detect/train11/weights/last.pt\")\n",
        "# CONTINUE TRAINING\n",
        "#model = YOLO(\"current_model.pt\") #load a previous model in case training interrupts\n",
        "\n",
        "# Train the model in increments\n",
        "epoch_increments = 50\n",
        "# while True:\n",
        "model.train(data=\"data.yaml\", epochs=epoch_increments, device=0, batch=16, degrees=360, flipud=0.5, fliplr=0.5, perspective=0.001, translate=0.1, scale=0.3,mosaic=0.5,mixup=0.5, pretrained=True, task='detect')  # train the model\n",
        "model.val()\n",
        "#shutil.copyfile(\"runs/detect/train\" + str(i) + \"/weights/best.pt\", \"/content/drive/My Drive/AUV_model_\" + str(i) + \".pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vcV3fZqHXxPW"
      },
      "outputs": [],
      "source": [
        "def visualizeBbox(img, bbox, class_name, thickness=2, fontSize=0.5):\n",
        "    #get xmin, xmax, ymin, ymax from bbox\n",
        "    BOX_COLOR=(0,255,0)\n",
        "    TEXT_COLOR = (0,0,0)\n",
        "    x_center, y_center, w, h = bbox\n",
        "    x_min = x_center - w/2\n",
        "    y_min = y_center - h/2\n",
        "    x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n",
        "    #draw bounding box on image\n",
        "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=BOX_COLOR, thickness=thickness)\n",
        "    #get size of class name text\n",
        "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, fontSize, 1)\n",
        "    #draw box around class name label on image\n",
        "    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
        "    #put class name text in the box we drew\n",
        "    cv2.putText(\n",
        "        img,\n",
        "        text=class_name,\n",
        "        org=(x_min, y_min - int(0.3 * text_height)),\n",
        "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        fontScale=fontSize,\n",
        "        color=TEXT_COLOR,\n",
        "        lineType=cv2.LINE_AA,\n",
        "    )\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6Tpx-d_3Mj5"
      },
      "source": [
        "# Predict on image with model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UdXmFvGW3Q8J",
        "outputId": "caff4afd-cec7-4bdf-9c34-085cecffd61e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 384x640 1 Earth Symbol, 1 Octagon Table, 101.6ms\n",
            "Speed: 3.7ms preprocess, 101.6ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([5., 2.], device='cuda:0')\n",
            "conf: tensor([0.8556, 0.3383], device='cuda:0')\n",
            "data: tensor([[1.8616e+02, 0.0000e+00, 8.5335e+02, 5.4959e+02, 8.5564e-01, 5.0000e+00],\n",
            "        [4.5889e+01, 8.6485e+01, 6.0198e+02, 4.4967e+02, 3.3832e-01, 2.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (561, 994)\n",
            "shape: torch.Size([2, 6])\n",
            "xywh: tensor([[519.7531, 274.7956, 667.1948, 549.5912],\n",
            "        [323.9359, 268.0766, 556.0939, 363.1833]], device='cuda:0')\n",
            "xywhn: tensor([[0.5229, 0.4898, 0.6712, 0.9797],\n",
            "        [0.3259, 0.4779, 0.5595, 0.6474]], device='cuda:0')\n",
            "xyxy: tensor([[186.1556,   0.0000, 853.3505, 549.5912],\n",
            "        [ 45.8889,  86.4849, 601.9828, 449.6682]], device='cuda:0')\n",
            "xyxyn: tensor([[0.1873, 0.0000, 0.8585, 0.9797],\n",
            "        [0.0462, 0.1542, 0.6056, 0.8015]], device='cuda:0')\n",
            "\n",
            "prediction:[tensor([519.7531, 274.7956, 667.1948, 549.5912], device='cuda:0'), tensor([323.9359, 268.0766, 556.0939, 363.1833], device='cuda:0')]\n",
            "\n",
            "prediction:[tensor(0.8556, device='cuda:0'), tensor(0.3383, device='cuda:0')]\n",
            "\n",
            "prediction:[tensor(5., device='cuda:0'), tensor(2., device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "img_path = \"data/augmented/test/images/img105.png\"\n",
        "img = cv2.imread(img_path)\n",
        "# Load a model\n",
        "model = YOLO(\"runs/detect/train3/weights/best.pt\")  # load a model\n",
        "# Use the model\n",
        "pred = model(img)\n",
        "for results in pred:\n",
        "    box = results.boxes\n",
        "    print(box)\n",
        "    print(\"\\nprediction:\" + str(list(box.xywh)))\n",
        "    print(\"\\nprediction:\" + str(list(box.conf)))\n",
        "    print(\"\\nprediction:\" + str(list(box.cls)))\n",
        "\n",
        "points = box.xywh.tolist()[0]\n",
        "boxed = visualizeBbox(img,points,\"gate\")\n",
        "cv2.imwrite(\"test.png\",boxed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MaXSVf1PXxPX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "e7482a8f-b7f1-45f9-cf31-8061d6b4c447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.207 🚀 Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/train3/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 10, 8400) (6.0 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.1.0+cu118...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ✅ 3.6s, saved as 'runs/detect/train3/weights/best.torchscript' (11.9 MB)\n",
            "\n",
            "Export complete (6.9s)\n",
            "Results saved to \u001b[1m/content/runs/detect/train3/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=runs/detect/train3/weights/best.torchscript imgsz=640  \n",
            "Validate:        yolo val task=detect model=runs/detect/train3/weights/best.torchscript imgsz=640 data=data.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'runs/detect/train3/weights/best.torchscript'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "model.export()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "MAQ76bSTy48-",
        "COpq9wZczt1G"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}